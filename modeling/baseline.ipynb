{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eQNQva0E0w5J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType, StructField, LongType\n",
    "\n",
    "import statsmodels.tsa.stattools as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start session\n",
    "spark = SparkSession.builder.master(\"local[5]\").appName(\"groupbyagg\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      date|sunspots|\n",
      "+----------+--------+\n",
      "|1749-01-31|    96.7|\n",
      "+----------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('hdfs://cluster-7b78-m/user/dataproc/Sunspots.csv',inferSchema=True,header=True)\n",
    "data = data.withColumnRenamed('Monthly Mean Total Sunspot Number', 'sunspots')\n",
    "data = data.select(to_date(col(\"date\"),\"yyyy-mm-dd\").alias(\"date\"), 'sunspots')\n",
    "data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- sunspots: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjiaIGMH0p2B"
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tbOKNxba0h82"
   },
   "outputs": [],
   "source": [
    "def data_for_modeling(data, forecast_months):\n",
    "  # create label \n",
    "  lead_window = Window.rowsBetween(0,forecast_months)   \n",
    "  data = data.withColumn(\"label\", last(data['sunspots']).over(lead_window))\n",
    "  \n",
    "  # vector assembler\n",
    "  data = data.dropna()\n",
    "  assembler = VectorAssembler().setInputCols(features).setOutputCol(\"features\")\n",
    "  data_transformed = assembler.transform(data)\n",
    "\n",
    "  return(data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WiMGeMqK0lhs"
   },
   "outputs": [],
   "source": [
    "def create_ts_vars(data, n_lags, features):\n",
    "\n",
    "  ## LAG VARS ######################################################################\n",
    "  # add col to partition by\n",
    "  data = data.withColumn(\"Series\",lit('Univariate'))\n",
    "\n",
    "  # set up window\n",
    "  lag_window = Window.orderBy(\"Series\")\n",
    "\n",
    "  for i in range(n_lags):\n",
    "      str_lag = 'sunspots'+'_lag_'+str(i+1)\n",
    "      data = data.withColumn(str_lag, lag(data['sunspots'], i+1).over(lag_window))\n",
    "      features.append(str_lag)\n",
    "      \n",
    "  data = data.drop('Series')   \n",
    "\n",
    "  ## MOVING AVG VAR ##############################################################\n",
    "  mavg_window = Window.rowsBetween(-n_lags, 0)\n",
    "  str_mov_avg = 'sunspots'+'_' + str(n_lags)+'_moving_avg'\n",
    "  data = data.withColumn(str_mov_avg, avg(data['sunspots']).over(mavg_window))\n",
    "  features.append(str_mov_avg)\n",
    "\n",
    "  ## TREND VAR ###################################################################\n",
    "  # if current sunspots > time-lagged sunspots then sign = +1.0\n",
    "  # if current sunspots < time-lagged sunspots then sign = -1.0\n",
    "  data = data.withColumn(\"Series\",lit('Univariate'))       \n",
    "  trend_window = Window.orderBy(\"Series\")\n",
    "  for i in range(n_lags):\n",
    "      str_sign = 'sunspots' +'_lag_'+str(i+1)+'_sign'\n",
    "      data = data.withColumn(str_sign,\\\n",
    "                          signum((data['sunspots'] - lag(data['sunspots'],i+1).over(trend_window))))\n",
    "      features.append(str_sign)\n",
    "      \n",
    "  data = data.drop(\"Series\")\n",
    "  \n",
    "  return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1QbAISFK0nzT"
   },
   "outputs": [],
   "source": [
    "def split_time_series(data, train_ratio=0.7):\n",
    "     \n",
    "    # split data into train and test but maintain time-order\n",
    "    newSchema  = StructType(data.schema.fields + \\\n",
    "                [StructField('Row Number', LongType(), False)])\n",
    "    new_rdd = data.rdd.zipWithIndex().map(lambda x: list(x[0]) + [x[1]])\n",
    "\n",
    "    # create new df with row number\n",
    "    new_df = spark.createDataFrame(new_rdd, newSchema)\n",
    "    total_rows = new_df.count()\n",
    "    splitFraction  =int(total_rows*train_ratio)\n",
    "\n",
    "    df_train = new_df.where(new_df['Row Number'] >= 0)\\\n",
    "                   .where(new_df['Row Number'] <= splitFraction)\n",
    "    df_test = new_df.where(new_df['Row Number'] > splitFraction)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SVra-NUz0SJ2"
   },
   "outputs": [],
   "source": [
    "def lr_fxn(train, test):\n",
    "  # init model\n",
    "  lr = LinearRegression(featuresCol = \"features\", labelCol=\"label\", \\\n",
    "                                maxIter = 100, regParam = 0.4, \\\n",
    "                                elasticNetParam = 0.1)\n",
    "  \n",
    "  # fit model \n",
    "  model = lr.fit(train)\n",
    "  pred_train = model.transform(train)\n",
    "  pred_test = model.transform(test)\n",
    "  \n",
    "\n",
    "  # calc rmse\n",
    "  evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName =\"rmse\")\n",
    "  RMSE_train = evaluator.evaluate(pred_train)\n",
    "  RMSE_test= evaluator.evaluate(pred_test)\n",
    "\n",
    "  return train, test, pred_train, pred_test, RMSE_train, RMSE_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRjLBo0P0uW2"
   },
   "source": [
    "Set up data for baseline (no lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "afQmsQIO0U7R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------------+\n",
      "|      date|sunspots|sunspots_0_moving_avg|\n",
      "+----------+--------+---------------------+\n",
      "|1749-01-31|    96.7|                 96.7|\n",
      "|1749-02-28|   104.3|                104.3|\n",
      "|1749-03-31|   116.7|                116.7|\n",
      "|1749-04-30|    92.8|                 92.8|\n",
      "|1749-05-31|   141.7|                141.7|\n",
      "|1749-06-30|   139.2|                139.2|\n",
      "|1749-07-31|   158.0|                158.0|\n",
      "|1749-08-31|   110.5|                110.5|\n",
      "|1749-09-30|   126.5|                126.5|\n",
      "|1749-10-31|   125.8|                125.8|\n",
      "+----------+--------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_lags = 12*0\n",
    "data_lag = data.select('*')\n",
    "features = ['sunspots']\n",
    "forecast_months = 10\n",
    "\n",
    "data_lag = create_ts_vars(data_lag, n_lags, features)\n",
    "data_lag.show(10)\n",
    "\n",
    "data_transformed = data_for_modeling(data_lag, forecast_months)\n",
    "\n",
    "train, test = split_time_series(data_transformed, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeXZxiWm0r5P"
   },
   "source": [
    "Run Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KJJwxRbViIIZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      date|label|        prediction|\n",
      "+----------+-----+------------------+\n",
      "|1749-01-31|264.3| 91.77509465637611|\n",
      "|1749-02-28|142.0| 97.46804704889298|\n",
      "|1749-03-31|122.2| 106.7565483208942|\n",
      "|1749-04-30|126.5| 88.85371119179509|\n",
      "|1749-05-31|148.7|125.48336540154179|\n",
      "+----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_train, lr_test, lr_pred_train, lr_pred_test, lr_RMSE_train, lr_RMSE_test = lr_fxn(train, test)\n",
    "\n",
    "lr_pred_train.select(['date', 'label','prediction']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dbox0b440MbY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.62770506935491"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SSYFTVuz0OQU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.11870682371968"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNBXls69oaVuoppRmomyl4B",
   "name": "baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
